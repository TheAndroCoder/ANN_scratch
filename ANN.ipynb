{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back Propagation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VBdhoX4UQ3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/wheat-seeds.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_iPO8uFZzZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b4340dee-06ef-43ac-dd3f-528cd7c5206a"
      },
      "source": [
        "#We will not use pandas to load dataframe this is only for viewing the dataset\n",
        "import pandas as pd\n",
        "df=pd.read_csv('wheat-seeds.csv',header=None)\n",
        "df[7].unique()\n",
        "print(df.info())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 210 entries, 0 to 209\n",
            "Data columns (total 8 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       210 non-null    float64\n",
            " 1   1       210 non-null    float64\n",
            " 2   2       210 non-null    float64\n",
            " 3   3       210 non-null    float64\n",
            " 4   4       210 non-null    float64\n",
            " 5   5       210 non-null    float64\n",
            " 6   6       210 non-null    float64\n",
            " 7   7       210 non-null    int64  \n",
            "dtypes: float64(7), int64(1)\n",
            "memory usage: 13.2 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6218nhjRU2Gp",
        "colab_type": "text"
      },
      "source": [
        "This Tutorial has been broken down into 6 parts...\n",
        "1. Initialise network\n",
        "2. Forward Propagate\n",
        "3. Back Propagate Error\n",
        "4. Train Network\n",
        "5. Predict\n",
        "6. Evaluate Prediction model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnft8M9ZVZaa",
        "colab_type": "text"
      },
      "source": [
        "# 1. Initialise Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoxbR29nWKeO",
        "colab_type": "text"
      },
      "source": [
        "The Network is organised into layers and each layer is made of various neurons. The input layer is just a row of our dataset. The first real layer is the hidden layer. It is followed by the output layer which has one neuron for each class value.\n",
        "We will organise layers as arrays of dictionaries and the whole network as an array of layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ8EZ_oKW-Rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_network(n_inputs,n_hidden,n_outputs):\n",
        "    network=list()\n",
        "    hidden_layer = [{'weights':[random() for i in range(n_inputs+1)]} for i in range(n_hidden)]\n",
        "    network.append(hidden_layer)\n",
        "    output_layer = [{'weights':[random() for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
        "    network.append(output_layer)\n",
        "    return network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuE7kjr8Zhwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8c0d8194-9649-42e6-b493-ad5471d85215"
      },
      "source": [
        "from random import random\n",
        "network = initialize_network(2,1,2)\n",
        "for layer in network:\n",
        "    print(layer)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'weights': [0.16806403492875022, 0.2817280053097815, 0.9126240487200058]}]\n",
            "[{'weights': [0.39125701682384595, 0.8881015975640839]}, {'weights': [0.4697303308232721, 0.32094778001391355]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PctnFQKLc2N1",
        "colab_type": "text"
      },
      "source": [
        "# 2. Forward Propagate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UH_C_XUd0Ca",
        "colab_type": "text"
      },
      "source": [
        "We can calculate output from a neural network by propagating an input signal through the network until the output layer outputs its values.\n",
        "We call this forward propagation.<br>\n",
        "We can break forward propagation into 3 steps :\n",
        "1. Neuron Activation\n",
        "2. Neuron Transfer\n",
        "3. Forward Propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir4wnSfne8dc",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Neuron Activation\n",
        "Neuron activation is calculated as the weighed sum of inputs just like Linear Regression.<br>\n",
        "<code>activation=sum(weight_i*input_i)+bias</code><br>\n",
        "The activate function assumes that the bias is the last weight in the list of weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfCwCz14fFSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activate(weights,inputs):\n",
        "    activation=weights[-1]\n",
        "    for i in range(len(weights)-1):\n",
        "       activation+=weights[i]*inputs[i]\n",
        "    return activation "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHLjuYHXhEV8",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Neuron Transfer\n",
        "Once neuron is activated we need to transfer the activation to see what the output is<br>\n",
        "Different transfer functions can be used but it is traditional to use sigmoid activation function\u0010 but you can also use hyperbolic tangent or Relu Activation.<br>\n",
        "**Sigmoid activation**<br>\n",
        "<code>output = 1/(1+e^-activation)</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9F2crQoiH--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import exp\n",
        "def transfer(activation):\n",
        "    return 1/(1+exp(-activation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQy8h2NCjSm4",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Forward Propagation\n",
        "We propagate the data from input layer calculating the output of each neuron. All of the output of one layer becomes input to next layer neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX2vFBunmw7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagate(network,row):\n",
        "    inputs=row\n",
        "    for layer in network:\n",
        "        new_inputs=[]\n",
        "        for neuron in layer:\n",
        "            activation=activate(neuron['weights'],inputs)\n",
        "            neuron['output']=transfer(activation)\n",
        "            new_inputs.append(neuron['output'])\n",
        "        inputs=new_inputs\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qYyf9ihnwoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0eca34b-557e-4234-a969-43b0051db293"
      },
      "source": [
        "print(forward_propagate(network,[1,0,None]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6594075188749586, 0.6870411377882268]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBlDhR1GoxpK",
        "colab_type": "text"
      },
      "source": [
        "# 3. Back Propagation\n",
        "Error is calculated between the actual outputs and the output forward propagated from the network\n",
        "<br>This part is broken down into 2 sections:\n",
        "<br>\n",
        "1. Transfer Derivative\n",
        "2. Error Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KGI-iLBpdK5",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Transfer Derivative\n",
        "Given an output from a neuron we need to calculate its slope.<br>\n",
        "We are using **Sigmoid activation function** the derivative of which can be calculated as<br>\n",
        "<code>derivative = output * (1.0 - output)</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlyQly06p-15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transfer_derivative(output):\n",
        "    return output*(1.0-output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgsmyu8iqI2u",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Error Backpropagation\n",
        "The first step is to calculate error for each output neuron<br>\n",
        "The error for a given neuron can be calculated as follows,<br>\n",
        "<code>error = (expected-output) * transfer_derivative(output)</code><br>\n",
        "This error calculation is used for calculating error in the output layer<br>\n",
        "The error signal for a neuron in hidden layer is little bit more complicated. It is calculated as weighted error of each layer in output neuron<br>\n",
        "<code>error = (weight_k * error_j) * transfer_derivative(output)</code><br>\n",
        "Where **error_j** is the error signal from the j-th neuron in the output layer, **weight_k** is the weight that connects k-th neuron to the current neuron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvpa8Dlv6O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward_propagate_error(network,expected):\n",
        "    for i in reversed(range(len(network))):\n",
        "        layer=network[i]\n",
        "        errors=list()\n",
        "        if i!=len(network)-1:\n",
        "            for j in range(len(layer)):\n",
        "                error=0.0\n",
        "                for neuron in network[i+1]:\n",
        "                    error+=neuron['weights'][j]*neuron['delta']\n",
        "                errors.append(error)\n",
        "        else:\n",
        "            for j in range(len(layer)):\n",
        "                neuron=layer[j]\n",
        "                errors.append(expected[j]-neuron['output'])\n",
        "        for j in range(len(layer)):\n",
        "            neuron=layer[j]\n",
        "            neuron['delta']=errors[j]*transfer_derivative(neuron['output'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbECyRUY_e3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
        "\tn_inputs = len(train[0]) - 1\n",
        "\tn_outputs = len(set([row[-1] for row in train]))\n",
        "\tnetwork = initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "\ttrain_network(network, train, l_rate, n_epoch, n_outputs)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\tprediction = predict(network, row)\n",
        "\t\tpredictions.append(prediction)\n",
        "\treturn(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaoyVrZH2uYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "98ebe6a1-4fad-4721-b99b-8b5c027a09f2"
      },
      "source": [
        "#Test back poropagation\n",
        "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
        "\t\t[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
        "expected = [0, 1]\n",
        "backward_propagate_error(network, expected)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': -0.0005348048046610517}]\n",
            "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': -0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': 0.0771723774346327}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUYBHJxi3ilU",
        "colab_type": "text"
      },
      "source": [
        "# 4. Train Network\n",
        "Network is trained using stochatic gradient descent\n",
        "<br>\n",
        "This involves multiple iterations of exposing a training dataset for each row of dataset, forward propagating the error and backward propagating the error\u0010 and updating the network weights<br>\n",
        "This part is broken down into two sections\n",
        "1. Update Weights\n",
        "2. Train Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5sfTr-74ORZ",
        "colab_type": "text"
      },
      "source": [
        "### 4.1. Update Weights\n",
        "Once error is calculated for each neuron using back propagation, they can be used to update weights<br>\n",
        "Network weights are updated as follows,<br>\n",
        "<code>weight += learning_rate * error * input</code><br>\n",
        "where **weight** is the given weight, **learning_rate** is a parameter, **error** is the error calculated by back propagation, and **input** is the input value that caused the error.<br>\n",
        "The same procedure can be used for updating the bias weights except that there is no input value, or input is the fixed value of 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuf45wso5fxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_weights(network,row,l_rate):\n",
        "    for i in range(len(network)):\n",
        "        inputs = row[:-1]\n",
        "        if i != 0:\n",
        "            inputs=[neuron['output'] for neuron in network[i-1]]\n",
        "        for neuron in network[i]:\n",
        "            for j in range(len(inputs)):\n",
        "                neuron['weights'][j]+=l_rate*neuron['delta']*inputs[j]\n",
        "            neuron['weights'][-1]+=l_rate*neuron['delta']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvQ6sEHa6jVB",
        "colab_type": "text"
      },
      "source": [
        "### 4.2. Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFiGhgEs6vlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(network,train,l_rate,n_epochs,n_outputs):\n",
        "    for epoch in range(n_epochs):\n",
        "        for row in train:\n",
        "            outputs = forward_propagate(network, row)\n",
        "            expected = [0 for i in range(n_outputs)]\n",
        "            expected[row[-1]] = 1\n",
        "            backward_propagate_error(network, expected)\n",
        "            update_weights(network, row, l_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryQmQNRV7xx_",
        "colab_type": "text"
      },
      "source": [
        "# 5. Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM1WTmdT7-aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(network,row):\n",
        "    outputs = forward_propagate(network,row)\n",
        "    return outputs.index(max(outputs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBCuXEOq8haR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from csv import reader\n",
        "from random import random\n",
        "from random import randrange\n",
        "from math import exp\n",
        "\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        " \n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
        "\treturn stats\n",
        " \n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)-1):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        " \n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor i in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        " \n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        " \n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k89aoFK91_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_csv(filename):\n",
        "    dataset=list()\n",
        "    with open(filename,'r') as file:\n",
        "        rows = reader(file)\n",
        "        for row in rows:\n",
        "            if not row:\n",
        "                continue\n",
        "            dataset.append(row)\n",
        "        return dataset "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeTUjGyj-RcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03a5e28d-d463-498f-8c8c-baa69aaac46d"
      },
      "source": [
        "dataset = load_csv('wheat-seeds.csv')\n",
        "for i in range(len(dataset[0])-1):\n",
        "    str_column_to_float(dataset,i)\n",
        "str_column_to_int(dataset,len(dataset[0])-1)\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset,minmax)\n",
        "scores = evaluate_algorithm(dataset,back_propagation,5,0.3,500,5)\n",
        "print(scores)\n",
        "print('Mean Accuracy ',sum(scores)/len(scores))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[97.61904761904762, 92.85714285714286, 90.47619047619048, 90.47619047619048, 97.61904761904762]\n",
            "Mean Accuracy  93.80952380952381\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}